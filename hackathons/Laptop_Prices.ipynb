{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chicken-orlando",
   "metadata": {},
   "source": [
    "<img src=images/gdd-logo.png align=right width=300px style='padding:20px'>\n",
    "\n",
    "\n",
    "# Hackathon: Laptop Prices\n",
    "\n",
    "You are about to be moved into a brand new team and everyone will need to buy a new laptop this time next year. Everyone has submitted some specifications they'd like their laptop to be (weight, RAM, memory, GPU, Manufacturer etc.) and you want to be able to estimate the cost of these new laptops.\n",
    "\n",
    "You have data on a collection laptops along with the prices that they are. Your model should be able to determine the price of the laptop based on the information you have.\n",
    "\n",
    "Since you want to keep costs down you want to be able to interpret your model so that you know which specifications/details cause the laptop's price to change the most and therefore what to suggest people compromise on the most to reduce costs.\n",
    "\n",
    "**You have chosen to build a Linear Regression so that you can easily interpret the model.**\n",
    "\n",
    "<img src=\"images/laptop.jpeg\" style=\"display: block;margin-left: auto;margin-right: auto;height: 200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-harvey",
   "metadata": {},
   "source": [
    "## About the Data \n",
    "\n",
    "The features in the dataset are described below:\n",
    "\n",
    "|Column|Type|Description|\n",
    "|---|---|---|\n",
    "| company| String |Laptop Manufacturer|\n",
    "| product |String |Brand and Model|\n",
    "| type_name |String |Type (Notebook, Ultrabook, Gaming, etc.)|\n",
    "| inches |Numeric|Screen Size|\n",
    "| screen_resolution |String| Screen Resolution|\n",
    "| screen_resolution_width |String| Screen Resolution width only|\n",
    "| screen_resolution_height |String| Screen Resolution height only|\n",
    "| cpu| String |Central Processing Unit (CPU)|\n",
    "| ram |String|Laptop RAM in GB|\n",
    "| memory_disk |String|Hard Disk Memory in GB|\n",
    "| memory_ssd |String|SSD Memory|\n",
    "| gpu |String| Graphics Processing Units (GPU)|\n",
    "| op_sys |String| Operating System|\n",
    "| weight |String| Laptop Weight in kilograms|\n",
    "| price |Numeric| Price (Euro)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "swiss-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "first-roman",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>laptop_id</th>\n",
       "      <th>company</th>\n",
       "      <th>product</th>\n",
       "      <th>type_name</th>\n",
       "      <th>inches</th>\n",
       "      <th>screen_resolution</th>\n",
       "      <th>screen_resolution_width</th>\n",
       "      <th>screen_resolution_height</th>\n",
       "      <th>cpu</th>\n",
       "      <th>ram</th>\n",
       "      <th>memory_disk</th>\n",
       "      <th>memory_ssd</th>\n",
       "      <th>gpu</th>\n",
       "      <th>op_sys</th>\n",
       "      <th>weight</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2560x1600</td>\n",
       "      <td>2560</td>\n",
       "      <td>1600</td>\n",
       "      <td>Intel Core</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>SSD</td>\n",
       "      <td>Intel</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1339.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Macbook Air</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1440x900</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "      <td>Intel Core</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Intel</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.34</td>\n",
       "      <td>898.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>HP</td>\n",
       "      <td>250 G6</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Intel Core</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>SSD</td>\n",
       "      <td>Intel</td>\n",
       "      <td>No OS</td>\n",
       "      <td>1.86</td>\n",
       "      <td>575.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>15.4</td>\n",
       "      <td>2880x1800</td>\n",
       "      <td>2880</td>\n",
       "      <td>1800</td>\n",
       "      <td>Intel Core</td>\n",
       "      <td>16</td>\n",
       "      <td>512</td>\n",
       "      <td>SSD</td>\n",
       "      <td>AMD</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2537.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2560x1600</td>\n",
       "      <td>2560</td>\n",
       "      <td>1600</td>\n",
       "      <td>Intel Core</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>SSD</td>\n",
       "      <td>Intel</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1803.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  laptop_id company      product  type_name  inches  \\\n",
       "0           0          1   Apple  MacBook Pro  Ultrabook    13.3   \n",
       "1           1          2   Apple  Macbook Air  Ultrabook    13.3   \n",
       "2           2          3      HP       250 G6   Notebook    15.6   \n",
       "3           3          4   Apple  MacBook Pro  Ultrabook    15.4   \n",
       "4           4          5   Apple  MacBook Pro  Ultrabook    13.3   \n",
       "\n",
       "  screen_resolution  screen_resolution_width  screen_resolution_height  \\\n",
       "0         2560x1600                     2560                      1600   \n",
       "1          1440x900                     1440                       900   \n",
       "2         1920x1080                     1920                      1080   \n",
       "3         2880x1800                     2880                      1800   \n",
       "4         2560x1600                     2560                      1600   \n",
       "\n",
       "          cpu  ram  memory_disk memory_ssd    gpu op_sys  weight    price  \n",
       "0  Intel Core    8          128        SSD  Intel  macOS    1.37  1339.69  \n",
       "1  Intel Core    8          128    Storage  Intel  macOS    1.34   898.94  \n",
       "2  Intel Core    8          256        SSD  Intel  No OS    1.86   575.00  \n",
       "3  Intel Core   16          512        SSD    AMD  macOS    1.83  2537.45  \n",
       "4  Intel Core    8          256        SSD  Intel  macOS    1.37  1803.60  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops = pd.read_csv('data/laptops.csv', encoding = \"ISO-8859-1\")\n",
    "laptops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-transportation",
   "metadata": {},
   "source": [
    "## Prepare `X` and `y`\n",
    "\n",
    "Split the data into `X` and `y` where `X` is the feature matrix and `y` is the target (`price`)\n",
    "\n",
    "Exclude `company`, `product` and `screen_resolution` from the feature matrix due to the large amount of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rising-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['laptop_id', 'type_name', 'inches',\n",
    "       'screen_resolution_width', 'screen_resolution_height', \n",
    "        'cpu', 'ram', 'memory_disk', 'memory_ssd', 'gpu', 'op_sys', 'weight']\n",
    "\n",
    "X = laptops.loc[:, features]\n",
    "y = laptops.loc[:, 'price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-gravity",
   "metadata": {},
   "source": [
    "Check the shape of `X` and `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pharmaceutical-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1302, 12), (1302,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-destruction",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Perform the train test split on the data to create `X_train`, `X_test`, `y_train`, `y_test`\n",
    "\n",
    "Use a `random_state` to ensure the split is the same each time it is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "designed-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-defensive",
   "metadata": {},
   "source": [
    "Check the shape of `X_train`, `X_test`, `y_train` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "changed-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train and y_train (976, 12) (976,)\n",
      "Shape of x_test and y_test (326, 12) (326,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train and y_train', X_train.shape, y_train.shape)\n",
    "print('Shape of x_test and y_test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-uganda",
   "metadata": {},
   "source": [
    "## Column Transformer\n",
    "\n",
    " Since there are categorical columns, we will need to encode these. First let's try out the one hot encoding. Import the `OneHotEncoder` from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-colleague",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Create a list of all the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bulgarian-damage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['type_name', 'cpu', 'memory_ssd', 'gpu', 'op_sys'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = X.select_dtypes('object').columns\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-persian",
   "metadata": {},
   "source": [
    "Since there are categorical columns, we will need to encode these. None are ordinal so we will use `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5d0e9",
   "metadata": {},
   "source": [
    "Now check to see if there is any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "potential-renaissance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "laptop_id                   0\n",
       "type_name                   0\n",
       "inches                      0\n",
       "screen_resolution_width     0\n",
       "screen_resolution_height    0\n",
       "cpu                         0\n",
       "ram                         0\n",
       "memory_disk                 0\n",
       "memory_ssd                  0\n",
       "gpu                         0\n",
       "op_sys                      0\n",
       "weight                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-plant",
   "metadata": {},
   "source": [
    "There are no missing values. \n",
    "\n",
    "Preprocessing needed:\n",
    "\n",
    "- Since we have categorical features that have no ranking, we will need to use `OneHotEncoder()`\n",
    "- Since we are building a `Linear Regression` we will want to `scale` the data so that the coefficients can be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-disaster",
   "metadata": {},
   "source": [
    "Now we need to build a column transformer so that we can only encode the categorical columns.\n",
    "\n",
    "- Import the `ColumnTransformer` from `sklearn.compose`\n",
    "- Instantiate the `ColumnTransformer()` with the `OneHotEncoder` on the categorical columns\n",
    "- Use the parameter `remainder='passthrough'` for the rest\n",
    "- use `.fit_transform()` with the column transformer on the `X_train` data and save this as `X_train_encoded`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "executed-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(976, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse=False), categorical_columns)\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_encoded = column_transformer.fit_transform(X_train)\n",
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-organizer",
   "metadata": {},
   "source": [
    "Now let's try out a scaler. **You can only do this on the encoded data since you cannot scale categorical features!!**\n",
    "\n",
    "Choose from the below and import it in from `sklearn.preprocessing`\n",
    "\n",
    "- `StandardScaler`\n",
    "- `RobustScaler`\n",
    "- `MinMaxScaler`\n",
    "\n",
    "Instantiate your scaler (eg. `scaler = RobustScaler()`) and try it out by performing:\n",
    "\n",
    "```python\n",
    "pd.DataFrame(scaler.fit_transform(X_train_encoded), columns=column_transformer.get_feature_names())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ranging-implement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehot__x0_Gaming</th>\n",
       "      <th>onehot__x0_Netbook</th>\n",
       "      <th>onehot__x0_Notebook</th>\n",
       "      <th>onehot__x0_Ultrabook</th>\n",
       "      <th>onehot__x0_Workstation</th>\n",
       "      <th>onehot__x1_Intel Core</th>\n",
       "      <th>onehot__x1_Intel Other</th>\n",
       "      <th>onehot__x2_Hybrid</th>\n",
       "      <th>onehot__x2_SSD</th>\n",
       "      <th>onehot__x2_Storage</th>\n",
       "      <th>...</th>\n",
       "      <th>onehot__x4_Windows 10</th>\n",
       "      <th>onehot__x4_Windows 7</th>\n",
       "      <th>onehot__x4_macOS</th>\n",
       "      <th>laptop_id</th>\n",
       "      <th>inches</th>\n",
       "      <th>screen_resolution_width</th>\n",
       "      <th>screen_resolution_height</th>\n",
       "      <th>ram</th>\n",
       "      <th>memory_disk</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>-1.124500</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>6.585107</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>-0.341621</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>1.037591</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.177424</td>\n",
       "      <td>5.818689</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>1.352103</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>0.050518</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>-0.098553</td>\n",
       "      <td>-0.539908</td>\n",
       "      <td>0.790295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.889284</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>-0.341621</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.963771</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.177424</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>1.431424</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>-1.066847</td>\n",
       "      <td>-1.062757</td>\n",
       "      <td>-0.844196</td>\n",
       "      <td>0.125709</td>\n",
       "      <td>0.056728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.889284</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>-0.341621</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>1.037591</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459258</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>-1.566898</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>0.050518</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>-0.844196</td>\n",
       "      <td>-0.889084</td>\n",
       "      <td>-0.227716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.889284</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>-0.341621</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.963771</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459258</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.445204</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>0.050518</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>-0.844196</td>\n",
       "      <td>1.489678</td>\n",
       "      <td>0.505850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.889284</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>-0.341621</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>1.037591</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459258</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.968720</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>-1.066847</td>\n",
       "      <td>-1.062757</td>\n",
       "      <td>-0.844196</td>\n",
       "      <td>-0.889084</td>\n",
       "      <td>0.176494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.889284</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>-0.341621</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.963771</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459258</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>-1.397680</td>\n",
       "      <td>1.580140</td>\n",
       "      <td>0.050518</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>-0.844196</td>\n",
       "      <td>1.489678</td>\n",
       "      <td>-0.092980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.889284</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>-2.355915</td>\n",
       "      <td>2.927222</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>1.037591</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459258</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.104125</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>-1.066847</td>\n",
       "      <td>-1.062757</td>\n",
       "      <td>-0.844196</td>\n",
       "      <td>-0.889084</td>\n",
       "      <td>-0.302570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>-1.124500</td>\n",
       "      <td>2.433513</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>-0.341621</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>1.037591</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459258</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>-1.484933</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>0.050518</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>-0.098553</td>\n",
       "      <td>-0.539908</td>\n",
       "      <td>-0.347483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>2.225134</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>-1.124500</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>-0.341621</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.963771</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459258</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.217818</td>\n",
       "      <td>1.580140</td>\n",
       "      <td>0.050518</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>-0.098553</td>\n",
       "      <td>-0.889084</td>\n",
       "      <td>0.954973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>-0.449411</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.889284</td>\n",
       "      <td>-0.410929</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>-2.355915</td>\n",
       "      <td>2.927222</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.963771</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.177424</td>\n",
       "      <td>-0.171860</td>\n",
       "      <td>-0.133142</td>\n",
       "      <td>0.627641</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>-1.066847</td>\n",
       "      <td>-1.062757</td>\n",
       "      <td>-0.844196</td>\n",
       "      <td>1.489678</td>\n",
       "      <td>-0.092980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>976 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     onehot__x0_Gaming  onehot__x0_Netbook  onehot__x0_Notebook  \\\n",
       "0            -0.449411           -0.133142            -1.124500   \n",
       "1            -0.449411           -0.133142             0.889284   \n",
       "2            -0.449411           -0.133142             0.889284   \n",
       "3            -0.449411           -0.133142             0.889284   \n",
       "4            -0.449411           -0.133142             0.889284   \n",
       "..                 ...                 ...                  ...   \n",
       "971          -0.449411           -0.133142             0.889284   \n",
       "972          -0.449411           -0.133142             0.889284   \n",
       "973          -0.449411           -0.133142            -1.124500   \n",
       "974           2.225134           -0.133142            -1.124500   \n",
       "975          -0.449411           -0.133142             0.889284   \n",
       "\n",
       "     onehot__x0_Ultrabook  onehot__x0_Workstation  onehot__x1_Intel Core  \\\n",
       "0               -0.410929                6.585107               0.424464   \n",
       "1               -0.410929               -0.151858               0.424464   \n",
       "2               -0.410929               -0.151858               0.424464   \n",
       "3               -0.410929               -0.151858               0.424464   \n",
       "4               -0.410929               -0.151858               0.424464   \n",
       "..                    ...                     ...                    ...   \n",
       "971             -0.410929               -0.151858               0.424464   \n",
       "972             -0.410929               -0.151858              -2.355915   \n",
       "973              2.433513               -0.151858               0.424464   \n",
       "974             -0.410929               -0.151858               0.424464   \n",
       "975             -0.410929               -0.151858              -2.355915   \n",
       "\n",
       "     onehot__x1_Intel Other  onehot__x2_Hybrid  onehot__x2_SSD  \\\n",
       "0                 -0.341621          -0.090909        1.037591   \n",
       "1                 -0.341621          -0.090909       -0.963771   \n",
       "2                 -0.341621          -0.090909        1.037591   \n",
       "3                 -0.341621          -0.090909       -0.963771   \n",
       "4                 -0.341621          -0.090909        1.037591   \n",
       "..                      ...                ...             ...   \n",
       "971               -0.341621          -0.090909       -0.963771   \n",
       "972                2.927222          -0.090909        1.037591   \n",
       "973               -0.341621          -0.090909        1.037591   \n",
       "974               -0.341621          -0.090909       -0.963771   \n",
       "975                2.927222          -0.090909       -0.963771   \n",
       "\n",
       "     onehot__x2_Storage  ...  onehot__x4_Windows 10  onehot__x4_Windows 7  \\\n",
       "0             -0.244372  ...              -2.177424              5.818689   \n",
       "1             -0.244372  ...              -2.177424             -0.171860   \n",
       "2             -0.244372  ...               0.459258             -0.171860   \n",
       "3             -0.244372  ...               0.459258             -0.171860   \n",
       "4             -0.244372  ...               0.459258             -0.171860   \n",
       "..                  ...  ...                    ...                   ...   \n",
       "971           -0.244372  ...               0.459258             -0.171860   \n",
       "972           -0.244372  ...               0.459258             -0.171860   \n",
       "973           -0.244372  ...               0.459258             -0.171860   \n",
       "974           -0.244372  ...               0.459258             -0.171860   \n",
       "975           -0.244372  ...              -2.177424             -0.171860   \n",
       "\n",
       "     onehot__x4_macOS  laptop_id    inches  screen_resolution_width  \\\n",
       "0           -0.133142   1.352103  0.385114                 0.050518   \n",
       "1           -0.133142   1.431424  0.385114                -1.066847   \n",
       "2           -0.133142  -1.566898  0.385114                 0.050518   \n",
       "3           -0.133142   0.445204  0.385114                 0.050518   \n",
       "4           -0.133142   0.968720  0.385114                -1.066847   \n",
       "..                ...        ...       ...                      ...   \n",
       "971         -0.133142  -1.397680  1.580140                 0.050518   \n",
       "972         -0.133142   0.104125  0.385114                -1.066847   \n",
       "973         -0.133142  -1.484933  0.385114                 0.050518   \n",
       "974         -0.133142   0.217818  1.580140                 0.050518   \n",
       "975         -0.133142   0.627641  0.385114                -1.066847   \n",
       "\n",
       "     screen_resolution_height       ram  memory_disk    weight  \n",
       "0                    0.029779 -0.098553    -0.539908  0.790295  \n",
       "1                   -1.062757 -0.844196     0.125709  0.056728  \n",
       "2                    0.029779 -0.844196    -0.889084 -0.227716  \n",
       "3                    0.029779 -0.844196     1.489678  0.505850  \n",
       "4                   -1.062757 -0.844196    -0.889084  0.176494  \n",
       "..                        ...       ...          ...       ...  \n",
       "971                  0.029779 -0.844196     1.489678 -0.092980  \n",
       "972                 -1.062757 -0.844196    -0.889084 -0.302570  \n",
       "973                  0.029779 -0.098553    -0.539908 -0.347483  \n",
       "974                  0.029779 -0.098553    -0.889084  0.954973  \n",
       "975                 -1.062757 -0.844196     1.489678 -0.092980  \n",
       "\n",
       "[976 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pd.DataFrame(scaler.fit_transform(X_train_encoded), columns = column_transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-paper",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "Now that we have a scaler chosen, we're ready to build a pipeline.\n",
    "\n",
    "- Import `Pipeline` from `sklrean.pipeline` and `LinearRegression` from `sklearn.linear_model`.\n",
    "- Instantiate the model with no parameters\n",
    "- Instantiate the pipeline with the scaler and model as the 2 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "successful-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "pipeline_lr = Pipeline(steps = [\n",
    "    ('onehot', column_transformer),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model_lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-organ",
   "metadata": {},
   "source": [
    "Fit the pipeline to `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "purple-going",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('onehot',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehot',\n",
       "                                                  OneHotEncoder(drop='first',\n",
       "                                                                sparse=False),\n",
       "                                                  Index(['type_name', 'cpu', 'memory_ssd', 'gpu', 'op_sys'], dtype='object'))])),\n",
       "                ('scaler', StandardScaler()), ('model', LinearRegression())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-sucking",
   "metadata": {},
   "source": [
    "## Performance metrics\n",
    "\n",
    "Find the $r^2$ score on both the train and the test. Is your model generalising well? Is your model overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "basic-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.7564135935097027\n",
      "Test set accuracy: 0.7237473407199873\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set accuracy:', pipeline_lr.score(X_train, y_train))\n",
    "print(f'Test set accuracy:', pipeline_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-papua",
   "metadata": {},
   "source": [
    "The high accuracy score on both train and test demonstrates a model that generalises well. Since the drop from train to test is minor, this also suggests that the model is not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58014bfb",
   "metadata": {},
   "source": [
    "# <mark>Assignment</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2eef1e",
   "metadata": {},
   "source": [
    "Try all explainability techniques discussed in this workshop on your model/a data point:\n",
    "1. Ceteris Paribus\n",
    "    b. Prediction Ceteris ParibusBreak-Down\n",
    "    c. Permutation Feature Importance\n",
    "    d. Partial Dependence Plots\n",
    "    </br>\n",
    "Then answer the following questions:\n",
    "1. Which features have the biggest influence on the laptop price? \n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7d700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "electrical-floating",
   "metadata": {},
   "source": [
    "<img src='images/gdd-logo.png' align=right width=300px>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
