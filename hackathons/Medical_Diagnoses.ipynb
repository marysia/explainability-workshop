{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "verbal-muslim",
   "metadata": {},
   "source": [
    "# Hackathon: Medical Diagnoses\n",
    "\n",
    "You are working for a hospital and you want to be able to detect a certain disease using data taken from medical images.\n",
    "\n",
    "You have data describing an image of a medical sample and knowledge of whether the patient the sample as taken from was diagnosed with the disease or not.\n",
    "\n",
    "You want to be able to capture every patient who need to be assessed further so as to rule out any complications related to the disease.\n",
    "\n",
    "\n",
    "<img src=\"images/doctor.png\" style=\"display: block;margin-left: auto;margin-right: auto;height: 300px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-richardson",
   "metadata": {},
   "source": [
    "## About the data\n",
    "\n",
    "This dataset comes from Scikit-Learn as one of the many datasets to explore and on which perform machine learning. [The Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset).\n",
    "\n",
    "The features in the dataset were computed from a digitized image of a breast tissue sample; they describe characteristics of the cell nuclei present in the image.\n",
    "\n",
    "\n",
    "|Column|Description|Type|\n",
    "|:---|:---|:---|\n",
    "|id|ID number|float|\n",
    "|diagnosis|The diagnosis of breast tissues (M = malignant, B = benign)|float|\n",
    "|radius_mean|mean of distances from center to points on the perimeter|float|\n",
    "|texture_mean|standard deviation of gray-scale values|float|\n",
    "|perimeter_mean|mean size of the perimeter of the tumor|float|\n",
    "|area_mean|mean size of the tumor|float|\n",
    "|smoothness_mean|mean of local variation in radius lengths|float|\n",
    "|compactness_mean|mean of perimeter^2 / area - 1.0|float|\n",
    "|concavity_mean|mean of severity of concave portions of the contour|float|\n",
    "|concave points_mean|mean for number of concave portions of the contour|float|\n",
    "|fractal_dimension_mean|mean for \"coastline approximation\" - 1|float|\n",
    "|radius_se|standard error for the mean of distances from center to points on the perimeter|float|\n",
    "|texture_se|standard error for standard deviation of gray-scale values|float|\n",
    "|perimeter_se|standard error for the perimeter of the tumor|float|\n",
    "|area_se|standard error for the size of the tumor|float|\n",
    "|smoothness_se|standard error for local variation in radius lengths|float|\n",
    "|compactness_se|standard error for perimeter^2 / area - 1.0|float|\n",
    "|concavity_se|standard error for severity of concave portions of the contour|float|\n",
    "|concave points_se|standard error for number of concave portions of the contour|float|\n",
    "|fractal_dimension_se|standard error for \"coastline approximation\" - 1|float|\n",
    "|radius_worst|\"worst\" or largest mean value for mean of distances from center to points on the perimeter|float|\n",
    "|texture_worst|\"worst\" or largest mean value for standard deviation of gray-scale values|float|\n",
    "|perimeter_worst|\"worst\" or largest mean value for mean of perimeter|float|\n",
    "|area_worst|\"worst\" or largest mean value for mean of area|float|\n",
    "|smoothness_worst|\"worst\" or largest mean value for local variation in radius lengths|float|\n",
    "|compactness_worst|\"worst\" or largest mean value for perimeter^2 / area - 1.0|float|\n",
    "|concavity_worst|\"worst\" or largest mean value for severity of concave portions of the contour|float|\n",
    "|concave points_worst|\"worst\" or largest mean value for number of concave portions of the contour|float|\n",
    "|fractal_dimension_worst|\"worst\" or largest mean value for \"coastline approximation\" - 1|float|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "medical = pd.read_csv('data/medical.csv')\n",
    "medical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-queue",
   "metadata": {},
   "source": [
    "## Prepare `X` and `y`\n",
    "\n",
    "Split the data into `X` and `y` where `X` is the feature matrix and `y` is the target (`price`)\n",
    "\n",
    "Exclude `id` from the feature matrix due to it being a unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-brand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "floating-credit",
   "metadata": {},
   "source": [
    "Check the shape of `X` and `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-cartoon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "streaming-fence",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Perform the train test split on the data to create `X_train`, `X_test`, `y_train`, `y_test`\n",
    "\n",
    "Use a `random_state` to ensure the split is the same each time it is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-turkish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "representative-woman",
   "metadata": {},
   "source": [
    "Check the shape of `X_train`, `X_test`, `y_train` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-destination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minor-brighton",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "There are no categorical values or missing values to deal with. However since we are building a `Logistic Regression` we will want to `scale` the data so that the coefficients can be compared.\n",
    "\n",
    "Choose from the below and import it in from `sklearn.preprocessing`\n",
    "\n",
    "- `StandardScaler`\n",
    "- `RobustScaler`\n",
    "- `MinMaxScaler`\n",
    "\n",
    "Instantiate your scaler (eg. `scaler = RobustScaler()`) and try it out by performing:\n",
    "\n",
    "```python\n",
    "pd.DataFrame(scaler.fit_transform(X_train), columns=features)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-engine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "raising-tourist",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "Now that we have a scaler chosen, we're ready to build a pipeline.\n",
    "\n",
    "- Import `Pipeline` from `sklearn.pipeline` and a model (e.g. `LogisticRegression` from `sklearn.linear_model`).\n",
    "- Instantiate the model with no parameters\n",
    "- Instantiate the pipeline with the scaler and model as the 2 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-thinking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "outside-casting",
   "metadata": {},
   "source": [
    "Fit the pipeline to `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-rolling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05d2c2b2",
   "metadata": {},
   "source": [
    "# <mark>Assignment</mark>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "493bb566",
   "metadata": {},
   "source": [
    "Try all explainability techniques discussed in this workshop on your model/a data point:\n",
    "    a. Ceteris Paribus\n",
    "    b. Prediction Ceteris ParibusBreak-Down\n",
    "    c. Permutation Feature Importance\n",
    "    d. Partial Dependence Plots\n",
    "\n",
    "Then answer the following questions:\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2c379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-strike",
   "metadata": {},
   "source": [
    "<img src='images/gdd-logo.png' align=right width=300px>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
